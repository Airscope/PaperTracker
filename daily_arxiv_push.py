import requests
import feedparser
from datetime import datetime, timezone
import os

# é…ç½®å…³é”®è¯ç»„åˆ
KEYWORDS = [
    "LLM", "GPT", '"large language model"', '"agent"',
    "chatgpt", "prompt", "fine-tune", "pretrain"
]

# æ„é€  arXiv API æŸ¥è¯¢
def fetch_today_llm_papers():
    today_utc = datetime.now(timezone.utc).date()
    query = "+OR+".join(f"all:{kw}" for kw in KEYWORDS)
    url = (
        f"http://export.arxiv.org/api/query?"
        f"search_query={query}&start=0&max_results=50"
        f"&sortBy=submittedDate&sortOrder=descending"
    )

    resp = requests.get(url)
    feed = feedparser.parse(resp.content)

    papers = []
    for entry in feed.entries:
        pub_date = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc).date()
        if pub_date != today_utc:
            continue

        title = " ".join(entry.title.split())
        authors = ", ".join(a.name for a in entry.authors)
        comment = getattr(entry, "arxiv_comment", "æ— å¤‡æ³¨")
        summary = entry.summary.strip().replace("\n", " ")
        summary_short = summary[:300] + ("..." if len(summary) > 300 else "")

        papers.append({
            "title": title,
            "authors": authors,
            "comment": comment,
            "summary_short": summary_short,
            "summary_full": summary,
            "link": entry.link
        })

    return papers


# æ„é€ é£ä¹¦å¯Œæ–‡æœ¬å¡ç‰‡æ ¼å¼
def build_feishu_card(papers):
    if not papers:
        return {
            "msg_type": "interactive",
            "card": {
                "header": {
                    "title": {
                        "tag": "plain_text",
                        "content": f"ğŸ“­ ä»Šæ—¥ï¼ˆ{datetime.now().strftime('%Y-%m-%d')}ï¼‰æ— æœ€æ–° LLM è®ºæ–‡"
                    }
                },
                "elements": []
            }
        }

    elements = []
    for paper in papers:
        content = (
            f"**æ ‡é¢˜ï¼š** {paper['title']}\n"
            f"**ä½œè€…ï¼š** {paper['authors']}\n"
            f"**å¤‡æ³¨ï¼š** {paper['comment']}\n"
            f"**æ‘˜è¦é¢„è§ˆï¼š**\n"
            f"```{paper['summary_short']}```\n"
            f"<collapse>\n```{paper['summary_full']}```\n</collapse>\n"
            f"[ğŸ”— æŸ¥çœ‹è®ºæ–‡]({paper['link']})"
        )

        elements.append({
            "tag": "div",
            "text": {
                "tag": "lark_md",
                "content": content
            }
        })

    return {
        "msg_type": "interactive",
        "card": {
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": f"ğŸ“š ä»Šæ—¥ LLM / GPT æœ€æ–°è®ºæ–‡ï¼ˆå…± {len(papers)} ç¯‡ï¼‰"
                }
            },
            "elements": elements
        }
    }


# å‘é€åˆ°é£ä¹¦æœºå™¨äºº Webhook
def send_to_feishu(card_json):
    webhook = os.environ.get("FEISHU_WEBHOOK")
    if not webhook:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ FEISHU_WEBHOOK")

    resp = requests.post(webhook, json=card_json)
    if resp.status_code != 200:
        print("âŒ é£ä¹¦æ¨é€å¤±è´¥:", resp.status_code, resp.text)
    else:
        print("âœ… æ¨é€æˆåŠŸï¼Œå…±å‘é€:", len(card_json.get("card", {}).get("elements", [])), "æ¡è®ºæ–‡")


def main():
    papers = fetch_today_llm_papers()
    card = build_feishu_card(papers)
    send_to_feishu(card)


if __name__ == "__main__":
    main()
